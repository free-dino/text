We can interpret [[5.2 The weak law of large numbers|the weak law of large numbers]] as stating that "$M_n$ converges to $\mu$"


> [!NOTE] Convergence of a Deterministic Sequence
> Let $a_1, a_2, \cdots$ be a sequence of real numbers, and let $a$ be another real number. We say that the sequence $a_n$ converges to $a$, or $\lim_{n \to \infty} a_n = a$ if $\forall \epsilon >0$, $\exists n_0 \in \R$ such that: 
> $$
> |a_n -a| \le \epsilon, \qquad  \forall n \ge n_0
> $$

Intuitively, if $\lim_{n \to \infty} a_n = a$, then for any given accuracy level $\epsilon$, $a_n$ must be within $\epsilon$ of $a$, when $n$ is large enough.


> [!NOTE] Convergence in Probability
> Let $Y_1, Y_2,\cdots$ be a sequence of random variable (not necessarily independent) and let $a \in \R$. We say that the sequence $Y_n$ converges to $a$ in probability, if for every $\epsilon > 0$, we have:
> $$\lim_{n \to \infty}\mathbf P(|Y_n -a| \ge \epsilon) = 0$$

-> the [[5.2 The weak law of large numbers|weak law of large numbers]] simply state that the sample mean converges in probability to the true mean $\mu$.

The [[5.1 Markov and Chebyshev inequalities#^1e36b3|Chebyshev inequality]] implies that if all $Y_n$ have the same mean $\mu$, and $\text{Var}(Y_n)$ converge to $0$, then $Y_n$ converges to $\mu$ in probability.



