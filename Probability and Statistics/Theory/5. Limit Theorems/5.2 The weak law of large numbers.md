
> [!NOTE] Weak law asserts that:
> The sample of a large number of independent identically distributed random variables is very close to true mean, with high probability

Consider a sequence $X_1, X_2, \cdots$ of independent identically distributed random variables with mean $\mu$ and variance $\sigma^2$. Define a sample's mean by: $$M_n = \frac{X_1 + \cdots + X_n}{n}$$
We have:  $$\E[M_n] = \frac{\E[X_1] + \cdots+ \E[X_2]}{n} = \frac{n\mu}{n} = \mu$$
And: $$\text{Var}(M_n) = \frac {\text{Var}(X_1 + \cdots + X_n)}{n^2} = \frac{\text{Var}(X_1) + \cdots + \text{Var}(X_2)}{n^2} = \frac {n\sigma^2}{n^2} = \frac {\sigma^2}{n}$$

Apply the [[5.1 Markov and Chebyshev inequalities#^1e36b3|Chebyshev inequality]], we obtain: $$\mathbf P(|M_n-\mu| \ge \epsilon) \le \frac {\sigma^2}{n\epsilon^2} \qquad \forall\epsilon>0$$
The only assumption needed is that $\E[X_i]$ is well defined.

>[!NOTE] The Weak Law of Large Numbers
>Let $X_1, X_2, \cdots$ be independent identically distributed random variables with mean $\mu$. For every $\epsilon > 0$, we have $$\mathbf P(|M_n - \mu| \ge \epsilon) = \mathbf P \Bigg ( \Bigg| \frac{X_1+\cdots + X_2}{n} - \mu \Bigg| \ge \epsilon \Bigg) \to 0, \qquad \text{as } n \to \infty$$





