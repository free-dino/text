**problem = program**
$\newcommand{\norm}[1]{\left \lVert #1 \right\rVert}$
## Optimization terminology

$$
\begin{flalign}
&\min_{x \in D} \qquad \qquad f(x)\\
&\text{subject to} \quad g_i(x) \le 0 ,\space i = 1,...,m \\
& \qquad \qquad \qquad Ax = b
\end{flalign}
$$
where $f$ and $g_i, \space i = 1,...,m$ are all convex, and the optimization domain is $D= \text{dom}(f) \cap \bigcap_{i=1}^{m} \text{dom}(g_i)$ 
* $f$ is called *criterion* or *objective* function
* $g_i$ is called *inequality constraint* function
* If $x \in D, \space g_i(x) \le 0, \space i = 1, ..., m$, and $Ax=b$ then $x$ is called a *feasible point*
* The minimum of $f(x)$ over all feasible points $x$ called the *optimal value*
* If $x$ is feasible and $f(x) = f^*$, then $x$ is called *optimal*; also called a *solution* or a *minimizer* 
* If $x$ is feasible and $f(x) \le f^* + \epsilon$, then $x$ is called $\epsilon \text{-suboptimal}$ 
* If $x$ is feasible and $g_i(x) = 0$ then we say $g_i$ is *active* at $x$
* Convex minimization can be reposed as concave maximization
  $$\min_x \qquad f(x) \iff \max_x \qquad -f(x)$$
  Both are called convex optimization problems.

### Solution set
Let $X_{\text{opt}}$ be the set of all solutions of convex problem, written
$$
\begin{flalign}
X_{\text{opt}} = \space &\arg\min_{x \in D} \qquad f(x)\\
&\text{subject to} \quad g_i(x) \le 0 ,\space i = 1,...,m \\
& \qquad \qquad \qquad Ax = b
\end{flalign}
$$
**Key property 1:**
* $X_\text{opt}$ is a convex set
**Key property 2:**
* if $f$ is strictly convex, then solution is unique

### Lasso 

^d2701c

Given $y \in \mathbb R^n, \space X \in \mathbb R^{n \times p}$, consider the lasso problem:
$$
\begin{flalign}
\min_\beta \qquad &\norm{y-X\beta}_2^2 \\
\text{subject to}\quad &\norm{\beta}_1 \le s
\end{flalign}
$$
### Huber loss
$$\sum_{i=1}^n \rho (y_i - x_i^T\beta), \quad \rho(z) = 
\begin{cases}
\frac{1}{2}z^2 & |z| \le \delta \\
\delta|z| - \frac{1}{2} \delta^2 & else
\end{cases}
$$

### Support vector machines
Given $y \in \{-1,1\}^n, \space X \in \mathbb R^{m \times p}$ with rows $x_1,..., x_n$ consider the support vector machine or SVM problem:
$$
\begin{flalign}
\min_{\beta, \beta_0, \xi} \qquad  &\frac{1}{2} \norm{\beta}_2^2 + C \sum_{i=1}^{n} \xi_i \\
\text{subject to} \quad &\xi_i \ge 0, \space i = 1,...,n \\
& y_i(x_i^T \beta + \beta_0)\ge 1-\xi_i, \space i=1,...,n
\end{flalign}
$$

### Local minima are global minima
For a convex problem, a feasible point $x$ is called locally optimal is there is some $R>0$ such that
$$f(x) \le f(y) \text{ for all feasible $y$ such that } \norm{x-y}_2 \le R$$
Reminder: for convex optimization problems, local optima are global optima

### Rewriting constraints
The optimization problem can be written as:
$$\min_x f(x) \text{ subject to } x \in C$$
where $C = \{x : g_i(x) \le 0, \space i = 1,...,m, \space Ax=b\}$, the feasible set. Hence the latter formulation is completely general

With $I_C$ the indicator of $C$, we can write this unconstrained form:
$$\min_x f(x)+ I_C(x)$$

## First-order optimality condition
For a convex problem:
$$\min_x f(x) \text{ subject to } x \in C$$
and differentiable of $f$, a feasible point $x$ is optimal if and only if 
$$\nabla f(x)^T(y-x) \ge 0 \text{ for all } y \in C$$
Important special case: if $C= \mathbb R^n$ (unconstrained optimization), then optimality condition reduces to familiar $\nabla f(x)=0$

### Quadratic minimization
Consider minimizing the quadratic function
$$f(x) = \frac{1}{2}x^TQx + b^Tx+c$$
where $Q \succeq 0$. The first order condition say that the solution satisfies: 
$$\nabla f(x) = Qx + b = 0$$
if $Q \succeq 0$ then there is a unique solution $x= -Q^{-1}b$
if $Q$ is singular and $b \not \in \text{col}(Q)$, then there is no solution. Cuz there are no $Q^{-1}$
if $Q$ is singular and $b \in \text{col}(Q)$, then there are infinitely many solutions
$$x = -Q^+ b + z, \qquad z \in \text{null}(Q)$$
where $Q^+$ is the pseudoinverse of $Q$

### Equality-constrained minimization
Consider the equality-constrained convex problem:
$$ \min_x f(x) \text{ subject to } Ax=b$$
with $f$ differentiable. Let's prove Lagrange multiplier optimality condition
$$ \nabla f(x) + A^Tu = 0 \quad \text{for some $u$}$$
According to first-order optimality, solution $x$ satisfies $Ax=b$ and
$$\nabla f(x)^T(y-x) \ge 0 \quad \text{ for all $y$ such that $Ay=b$}$$
This equivalent to
$$\nabla f(x)^Tv =0 \quad \forall v \in \text{null}(A)$$
Result follows because $\text{null}(A)^\bot = \text{row}(A)$ 

### Projection onto a convex set
Consider projection onto convex set C:
$$\min_x \norm{a-x}^2_2 \quad \text{subject to } x \in C$$
First-order optimality condition says that the solution $x$ satisfies
$$\nabla f(x)^T(y-x) = (x-a)^T(y-x) \ge 0 \quad \forall y \in C$$
Equivalently, this says that
$$a-x \in \mathcal N_C(x)$$
where recall $\mathcal N_C(x)$ is the normal cone to $C$ at $x$ 

### Partial optimization
Reminder : $g(x) = \min_{y\in C} f(x,y)$ is convex in $x$, provided that $f$ is convex in $(x,y)$ and $C$ is a convex set.
Therefore we can always partially optimize a convex problem and retain convexity
E.g., if we decompose $x=(x_1,x_2) \in \mathbb R^{n_1 + n_2}$, then
$$\begin{flalign*} 
& \begin{aligned} \min_{x_1,x_2} \quad &f(x_1,x_2) \\
\text{subject to} \quad &g_1(x_1)\leq 0 
\\ & g_2(x_2)\leq 0 
\end{aligned} 
& \iff \qquad 
& \begin{aligned} 
\min_{x_1} \quad &\tilde f(x_1) \\
\text{subject to} \quad &g_1(x_1)\leq 0 \\
\end{aligned} & 
\end{flalign*}
$$
where $\tilde f(x_1) = \min \{f(x_1,x_2) : g_2(x_2)\le 0\}$. The right problem is convex if the left problem is.

### Hinge form of SVMs
Recall the SVM problem
$$
\begin{flalign}
\min_{\beta, \beta_0, \xi} \qquad  &\frac{1}{2} \norm{\beta}_2^2 + C \sum_{i=1}^{n} \xi_i \\
\text{subject to} \quad &\xi_i \ge 0, \space i = 1,...,n \\
& y_i(x_i^T \beta + \beta_0)\ge 1-\xi_i, \space i=1,...,n
\end{flalign}
$$
Rewrite the constraints as $\xi_i \ge \max\{0,1-y_i(x_i^T \beta+ \beta_0)\}$. Indeed we can argue that we have equality at solution.

Therefore plugging in for optimal $\xi$ gives the hinge form of SVMs:
$$
\min_{\beta, \beta0} \frac{1}{2} \norm{\beta}^2_2 + C \sum_{i=1}^n [1-y_i(x_i^T \beta + \beta_0)]_{+}
$$
where $a_+ = \max\{0,a\}$ is called the hinge function

## Transformations and change of variables

If $h : \mathbb R \rightarrow \mathbb R$  is a monotone increasing transformation, then
$$
\begin{flalign}
&\min_x f(x) \quad \text{subjected to } x \in C \\
\iff &\min_x h(f(x)) \quad \text{subjected to} x \in C
\end{flalign}
$$
Similarly, inequality or equality constraints can be transformed and yield equivalent optimization problems. Can use this to reveal the "hidden convexity" of a problem

If $\phi : \mathbb R^n \rightarrow \mathbb R^m$ is one-to-one, and its image covers feasible set $C$, then we can change variables in an optimization problem: 
$$
\begin{flalign}
&\min_x f(x) \quad \text{subjected to } x \in C \\
\iff &\min_y f(\phi(y)) \quad \text{subjected to } \phi(y) \in C
\end{flalign}
$$

### Geometric programming
A monomial is a function $f: \mathbb R^n_{++} \rightarrow \mathbb R$ of the form
$$f(x) = \gamma \prod_{i=1}^n x_i^{a_i}$$
for $\gamma > 0$, $a_i \in \mathbb R$. A posynomial is a sum of monomial,
$$f(x) = \sum_{k=1}^p (\gamma k \prod_{i=1}^n x_i^{a_{ki}})$$
A geometric program is the form:
$$
\begin{flalign}
\min_{x} \qquad  &f(x)\\
\text{subject to} \quad &g_i(x) \le 1 ,\space i = 1,...,m \\
& h_j(x) = 1, \space j= 1,...,r
\end{flalign}
$$
where $f$, $g_i$, $i=1,...,m$ are posynomials and $h_j$, $j = 1,...,r$ are monomials. This is nonconvex.

Given $f(x) = \gamma \prod_{i=1}^n x_i^{a_i}$, let $y_i = \log x_i$ and rewrite this as $$
\gamma \prod_{i=1}^n (e^{y_i})^{a_i} = e^{a^Ty+b}
$$
for $b = \log\gamma$. Also, a posynomial can be written as $\sum_{k=1}^p e^{a_k^T y + b_k}$ 
With this variable substitution, and after taking logs, a geometric program is equivalent to 
$$
\begin{flalign}
\min_x \qquad &\log(\sum_{k=1}^{p_0} e^{a^T_{0k}y+b_{0k}})\\
\text{subject to } \quad & \log(\sum_{k=1}^{p_i} e^{a^T_{ik}y+b_{ik}})\le0, \space i =1,...,m \\
& c_j^Ty + d_j = 0, \space j=1,...,r
\end{flalign}
$$
This is convex, recalling the convexity of soft max functions
Several interesting problems are geometric program such as floor planning
See Boyd et al. (2007), “A tutorial on geometric programming”, and also Chapter 8.8 of B & V book

### Eliminating equality constraints
Important special case of change of variables: eliminating equality constraints. Given the problem
$$
\begin{flalign}
&\min_{x} \qquad \qquad f(x)\\
&\text{subject to} \quad g_i(x) \le 0 ,\space i = 1,...,m \\
& \qquad \qquad \qquad Ax = b
\end{flalign}
$$
we can always express any feasible point as $x= My + x_0$, where $Ax_0 = b$ and $\text{col}(M) = \text{null}(A)$. Hence the above is equivalent to
$$
\begin{flalign}
&\min_{y} \qquad \qquad f(My+x_0)\\
&\text{subject to} \quad g_i(My+x_0) \le 0 ,\space i = 1,...,m \\
& \qquad \qquad \qquad Ax = b
\end{flalign}
$$
Note: this is fully general but not always a good idea (practically)

### Introducing slack variables
Essentially opposite to eliminating equality constraint: introducing slack variables. Given the problem
$$
\begin{flalign}
\min_{x} \qquad \qquad &f(x)\\
\text{subject to} \qquad &g_i(x) \le 0 ,\space i = 1,...,m \\
& Ax = b
\end{flalign}
$$
we can transform the inequality constraints via
$$
\begin{flalign}
\min_{x,s} \qquad \qquad &f(x)\\
\text{subject to} \qquad &s_i\ge 0, \space i=1,...,m \\ 
&g_i(x) + s_i = 0 ,\space i = 1,...,m \\
& Ax = b
\end{flalign}
$$
Note: this is no longer convex unless $g_i$, $i=1,...,n$ are affine

### Relaxing nonaffine equalities
Given an optimization problem
$$\min_x \space f(x) \quad \text{subject to } x\in C$$
We can always take an enlarged constraint set $\tilde C \supseteq C$ and consider
$$\min_x f(x)  \text{ subjec to } x \in \tilde C$$
This is called a relaxation and its optimal value is always smaller or equal to that of the original problem.
Important special case: relaxing nonaffine equality constraints, such as
$$h_j(x) = 0,\space j=1,...,r$$
where $h_j, j=1,...,r$ are convex but non affine, are replace with
$$h_j(x)\le 0, \space j=1,...,r$$

### Maximum utility problem
The maximum utility problem models investment/consumption:
$$
\begin{flalign}
\max_{x,b} \qquad \qquad &\sum_{t=1}^T \alpha_tu(x_t)\\
\text{subject to} \qquad &b_{t+1} = b_t + f(b_t) -x_t, \space t = 1,...,T \\
& 0 \le x_t \le b_t, \space t= 1,...,T
\end{flalign}
$$
Here $b_t$ is the budget and $x_t$ is the amount consumed at time $t$; $f$ is an investment return function, both concave and increasing. (Here, say, $f(0)=0$, and $b_0>0$ is given)

// Is this a convex problem? What if we replace equality constraints with inequality:
$$
b_{t+1} \le b_t + f(b_t)-x_t, \space t = 1,...,T
$$

### Principal components analysis
Given $X \in \mathbb R^{n \times p}$, consider the low rank approximation problem:
$$
\min_{R} \norm{X-R}^2_F \quad \text{subject to } \text{rank}(R)=k
$$
Here $\norm{A}^2_F = \sum_{i=1}^n \sum_{j=1}^p A^2_{ij}$, the entrywise squared $\ell_2$ norm, and $\text{rank}(A)$ denotes the rank of $A$

Also called principal components analysis or PCA problem.
Given $X = UDV^T$, singular value decomposition or SVD, the solution is
$$R = U_kD_kV_k^T$$
where $U_k$, $V_k$ are the first $k$ columns of $U$, $V$ and $D_k$ is the first $k$ diagonal elements of $D$. That is, $R$ is reconstruction of X from its first $k$ principle components.
The PCA problem is not convex.
Rewrite as:
$$\min_{Z \ in \mathbb S^p} \norm{X-XZ}^2_F \text{ subject to } \text{rank}(Z) = k, \quad  Z\text{ is a projection }$$
$$
\iff \max_{Z \in \mathbb S^p} \text{tr}(SZ) \text{ subject to rank}(Z)=k, \quad \text{Z is a projection} 
$$
where $S=X^TX$. Hence constraints set is the nonconvex set
$$C = \{ Z \in \mathbb S^p: \lambda_i(Z) \in \{0,1\}, i=1,...,p, \space tr(Z) = k\}$$
where $\lambda_i(Z), \space i=1,...,n$ are the eigenvalues of Z. Solution in this formulation is
$$Z= V_kV_k^T$$
where $V_k$ gives first k columns of $V$

Consider relaxing constraints set to $\mathcal F_k = \text{conv}(C)$. Note
$$
\begin{flalign}
\mathcal F_k &= \{Z \in \mathbb S^p: \lambda_i(Z) \in [0,1], i=1,...,p, \text{tr}(Z)=k\} \\
&= \{Z \in \mathbb S^p : 0 \preceq Z \preceq\ I, \text{tr}(Z) = k \}
\end{flalign}
$$
This set is called the Fantope of order $k$. It's convex. Hence, the linear maximization over the Fantope, namely
$$\max_{Z \in \mathcal F_k}\space \text{tr}(SZ)$$
is a convex problem. Remarkably, this is equivalent to the original nonconvex PCA problem.