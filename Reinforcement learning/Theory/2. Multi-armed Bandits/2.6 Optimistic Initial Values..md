All the methods we have discussed so far are dependent t some extent on the initial [[2.5 Tracking a Nonstationary Problem#^a6519d|action-value estimates]], $Q_1(a)$ -> biased by their initial estimates.

For the [[2.2 Action-value Methods#^a154a8|sample-average methods]], the bias disappear once all actions have been selected at least once. 

For the methods with constant $\a$, the bias is permanent, though [[2.5 Tracking a Nonstationary Problem#^a6519d|decreasing over time]].

-> The initial estimates become a set of parameters that must be picked by the user.

Let the initial estimates to be positive instead of $0$ can be used as a simple way to encourage exploration.