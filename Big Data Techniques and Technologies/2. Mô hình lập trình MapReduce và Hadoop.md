# 1. Tổng quan về Hadoop
- Hadoop là một công nghệ phân tán và mã nguồn mở được sử dụng phổ biến để xử lý và lưu trữ khối dữ liệu lớn trên cá cụm máy tính phân tán, được thiết kế để xử lý và lưu trữ dữ liệu lớn một cách hiệu quả
- Đc phát triển dựa trên Google File System và MapReduce
- Hệ sinh thái Hadoop: ![[Pasted image 20241109224121.png]]
  - Hadoop sử dụng mô hình phân tán dữ liệu để lưu trữ và xử lý dữ liệu trên các máy tính thông thường
  - Hadoop phân chia dữ liệu thành các khối và lưu chúng trên nhiều máy tính, giúp tăng khả năng mở rộng, độ tin cậy và hiệu năng.
  - Hadoop phân tán dữ liệu trên nhiều nút máy tính và xử lý nó song song trên các nút, giúp giảm thời gian xử lý và tăng hiệu suất.
  - Có 3 thành phần chính: Hadoop Distributes FileSystem (HDFS), YARN và MapReduce
# 2. Mô hình MapReduce
## 2.1 MapReduce là gì?
- Lấy ý tưởng từ lập trình hàm
- Mô hình MapReduce:
	-  Là mô hình dùng cho xử lý tính toán song song và phân tán trên hệ thống phân tán. Gồm 2 bước:
	    - B1: Phân rã từ tác vụ (job) chính (do người dùng muốn thực hiện) thành các công việc con (task), chia về các máy tính trong hệ thống thực hiện xử lý một cách song song
	    - B2: Thu thập lại các kết quả
## 2.2 Quản lý thực thi công việc
- Hệ thống định nghĩa:
	- Một máy trong hệ thống đóng vai trò là master
	- Các máy còn lại đóng vai trò các worker (dựa trên kiến trúc Master-Slave)
- Master chịu trách nhiệm quản lý toàn bộ quá trình thực thi công việc trên hệ thống như:
	- Tiếp nhận công việc
	- Phân rã tác vụ thành công việc con
	- Phân các công việc con cho các worker
- Worker chỉ làm nhiệm vụ thực hiện công việc con được giao (map hoặc reduce)
- Quy trình thực hiện công việc:
	- B1: Chia dữ liệu đầu vào thành các mảnh dữ liệu
	- B2: Thực hiện công việc Map trên từng mảnh dữ liệu đầu vào
- => Xử lý song song các mảnh dữ liệu trên nhiều máy tính trong cụm
	- B3: Tổng hợp kết quả trung gian (sắp xếp, trộn)
	- B4: Sau khi tất cả công việc Map hoàn thành, thực hiện công việc Reduce trên từng mảnh dữ liệu trung gian
- => Thực hiện song song các mảnh dữ liệu trung gian trên nhiều máy tính trong cụm
	- B5: Tổng hợp kết quả hàm Reduce để cho kết quả cuối cùng
## 2.3 Ví dụ: Bài toán đếm từ
- Cho file text có:
	- Dear, Bear, River, Car, Car, River, Deep, Car, Bear

- B1: Splitting: Giả sử chia 3 phần
	  - P1: Dear, Bear, River
	  - P2: Car, Car, River
	  - P3: Deer, Car, Bear
- B2: Mapping:
	- Dear, Bear, River -> (Dear, 1), (Bear, 1), (River, 1)
	- Car, Car, River -> (Car, 1), (Car, 1), (River, 1)
	- Dear, Car, Bear -> (Dear, 1), (Car, 1), (Bear, 1)
- B3: Sorting & Shuffling:
	- Bear, (1, 1); Car, (1, 1, 1); Dear, (1, 1), River(1, 1)
- B4: Reducing
	- Bear, (1, 1) -> (Bear, 2)
	- Car, (1, 1, 1) -> (Car, 3)
	- Dear, (1, 1) -> (Dear, 2)
	- River, (1,1 ) -> (River, 2)
- B5: Tổng hợp kết quả của Reduce
	- (Bear, 2); (Car, 3); (Dear, 2); (River, 2)
## 2.4 Hàm map, reduce
- MapReduce dùng hai thao tác chính cho việc thực thi công việc là hàm Map và hàm Reduce
	- Hàm Map tiếp nhận mảnh dữ liệu input, rút thông tin cần thiết các phần tử, tạo kết quả trung gian
	- Hệ thống thực hiện một bước trung gian để trộn và sắp xếp lại kết quả
	- Hàm Reduce tổng hợp kết quả trung gian, tính toán để cho kết quả cuối cùng
- Hàm Map và Reduce được xem là phần xử lý quan trọng nhất trong mô hình MapReduce, do người dùng định nghĩa tùy theo nhu cầu sử dụng
- Giai đoạn reduce chỉ bắt đầu khi giai đoạn Map kết thúc.
- MapReduce định nghĩa dữ liệu dưới dạng cặp khóa/giá trị (key/value)
	- Linh hoạt hơn các bảng dữ liệu quan hệ 2 chiều truyền thống (khóa chính - khóa ngoại)
- Hàm map và reduce làm việc với khối dữ liệu dạng này
- Hàm map:
	- Input: một cặp (keyIn, valIn)
	- Output: danh sách các cặp (keyInt, valInt) trung gian (Intermediate)
	- Biểu diễn hình thực: map (keyIn, valIn) -> list (keyInt, valInt)
- Hàm reduce:
	- Input: một cặp (keyInt, list(valInt))
	- Output: danh sách các cặp: (keyOut, valOut)
	- Biểu diễn hình thức: reduce (keyInt, list(valInt)) -> list (keyOut, valOut)
## 2.5 Ưu điểm của mô hình MapReduce
- Xây dựng từ mô hình lập trình hàm và lập trình song song
- Giúp cải thiện tốc độ tính toán trên tập dữ liệu lớn bằng cách tăng tốc độ đọc ghi và xử lý dữ liệu 
- Có thể áp dụng hiệu quả trên nhiều bài toán
- Ẩn đi các chi tiết cài đặt và quản lý
## 2.6 Kiến trúc các thành phần
- Xét 1 cách trừu tượng, Hadoop MapReduce gồm 4 thành phần chính riêng biệt
	- **Client Program**: Chương trình HadoopMapReduce client sử dụng để chạy 1 MapReduce Job
	- **Job Tracker**:
		- Tiếp nhận job và đảm nhận vai trò điều phối job này
		- Có vai trò như bộ não của Hadoop MapReduce
		- Chia nhỏ job thành các task
		- Lập lịch phân công các task (map task, reduce task) này đến các TaskTracker để thực hiện
		- Có cấu trúc dữ liệu riêng để sử dụng cho mục đích lưu trữ: lưu lại tiến độ thể hiện của từng job, lưu lại trạng thái của TaskTracker để thuận tiện cho thao tác lên lịch phân công task, lưu lại địa chỉ lưu trữ của các output của các TaskTracker thực hiện MapTask trả về.
	- **TaskTracker**:
		- Tiếp nhận MapTask hay ReduceTask từ JobTracker để sau đó thực hiện
		- Để giữ liên lạc với JobTracker, Hadoop MapReduce cung cấp cơ chế gửi heartbeat từ TaskTracker đến JobTracker cho các như cầu như thông báo tiến độ của task do TaskTracker đó thực hiện, thông báo trạng thái hiện hành của nó: idle, in-progress, completed
	- **HDFS**:
		- Hệ thống file phân tán được dùng cho việc chia sẻ các file dùng trong cả quá trình xử lý một job giữa các thành phần trên với nhau

- Client Program $\xrightarrow{\text{Submit Job}}$ JobTracker $\xrightarrow{\text{Phân công }}$ Task Tracker 
## 2.7 Cơ chế hoạt động
- Submit Job và chuẩn bị dữ liệu
- Quản lý Job và chia task
- Liên lạc giữa JobTracker và TaskTracker
- Làm việc ở MapTaskTracker
- Làm việc ở ReduceTaskTracker
### 2.7.1 Submit Job và chuẩn bị dữ liệu
- Client gửi yêu cầu thực hiện job và kèm theo dữ liệu input tới JobTracker
- JobTracker thông báo cho client tình trạng tiếp nhận job
- Nếu tình trạng tiếp nhận hợp lệ, client tiến hành phân rã input này thành các split và ghi vào HDFS
- Client gửi thông báo sẵn sàng để JobTracker biết việc chuẩn bị dữ liệu thành công và tiền hành thực hiện job
### 2.7.2 Quản lý Job và chia Task
- Khi nhận được thông báo sẵn sàng từ client, JobTracker đưa job này vào một danh sách lưu các Job mà các client yêu cầu thực hiện
- Tại một thời điểm JobTracker chỉ thực hiện một job
- Sau khi một job hoàn thành hay bị block, JobTracker sẽ lấy job khác trong list này (FIFO) ra thực hiện
- JobTracker có một job scheduler với nhiệm vụ lấy vị trí các split (từ HDFS do chương trình client tạo ra) và sau đó tạo một danh sách các task để thực thi
- Mỗi split có một maptask để thực thi -> số lượng maptask bằng với số lượng split
- JobTracker lưu trữ thông tin trạng thái và tiến độ của tất cả các task.