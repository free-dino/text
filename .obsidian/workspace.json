{
  "main": {
    "id": "a3bfb49a9a2b37ab",
    "type": "split",
    "children": [
      {
        "id": "50b312da58068a81",
        "type": "tabs",
        "children": [
          {
            "id": "b8c5e33dba75b402",
            "type": "leaf",
            "state": {
              "type": "markdown",
              "state": {
                "file": "Reinforcement learning/Theory/3. Finite Markov Decision Processes/3.1 The Agent-Environment Interface.md",
                "mode": "source",
                "source": false
              },
              "icon": "lucide-file",
              "title": "3.1 The Agent-Environment Interface"
            }
          }
        ]
      }
    ],
    "direction": "vertical"
  },
  "left": {
    "id": "9c48fad478e93c46",
    "type": "split",
    "children": [
      {
        "id": "fb69300ad9e36610",
        "type": "tabs",
        "children": [
          {
            "id": "df118089bc0652cc",
            "type": "leaf",
            "state": {
              "type": "file-explorer",
              "state": {
                "sortOrder": "alphabetical"
              },
              "icon": "lucide-folder-closed",
              "title": "Files"
            }
          },
          {
            "id": "f11ebfea6d001833",
            "type": "leaf",
            "state": {
              "type": "search",
              "state": {
                "query": "",
                "matchingCase": false,
                "explainSearch": false,
                "collapseAll": false,
                "extraContext": false,
                "sortOrder": "alphabetical"
              },
              "icon": "lucide-search",
              "title": "Search"
            }
          },
          {
            "id": "bc93ec5b0a99aba2",
            "type": "leaf",
            "state": {
              "type": "bookmarks",
              "state": {},
              "icon": "lucide-bookmark",
              "title": "Bookmarks"
            }
          }
        ]
      }
    ],
    "direction": "horizontal",
    "width": 294.5
  },
  "right": {
    "id": "e49f6b232a5cc208",
    "type": "split",
    "children": [
      {
        "id": "27bc4972f5293b4f",
        "type": "tabs",
        "children": [
          {
            "id": "fb47815bacac5d57",
            "type": "leaf",
            "state": {
              "type": "tag",
              "state": {
                "sortOrder": "frequency",
                "useHierarchy": true
              },
              "icon": "lucide-tags",
              "title": "Tags"
            }
          },
          {
            "id": "99d920b2ffffaccd",
            "type": "leaf",
            "state": {
              "type": "backlink",
              "state": {
                "file": "Reinforcement learning/Theory/2. Multi-armed Bandits/2.6 Optimistic Initial Values..md",
                "collapseAll": false,
                "extraContext": false,
                "sortOrder": "alphabetical",
                "showSearch": false,
                "searchQuery": "",
                "backlinkCollapsed": false,
                "unlinkedCollapsed": true
              },
              "icon": "links-coming-in",
              "title": "Backlinks for 2.6 Optimistic Initial Values."
            }
          },
          {
            "id": "f5145fb05187313e",
            "type": "leaf",
            "state": {
              "type": "outgoing-link",
              "state": {
                "file": "Reinforcement learning/Theory/2. Multi-armed Bandits/2.6 Optimistic Initial Values..md",
                "linksCollapsed": false,
                "unlinkedCollapsed": true
              },
              "icon": "links-going-out",
              "title": "Outgoing links from 2.6 Optimistic Initial Values."
            }
          },
          {
            "id": "7b75a4d2d8fb5970",
            "type": "leaf",
            "state": {
              "type": "outline",
              "state": {
                "file": "Reinforcement learning/Theory/2. Multi-armed Bandits/2.6 Optimistic Initial Values..md"
              },
              "icon": "lucide-list",
              "title": "Outline of 2.6 Optimistic Initial Values."
            }
          },
          {
            "id": "6b157d9c4bb60602",
            "type": "leaf",
            "state": {
              "type": "git-view",
              "state": {},
              "icon": "git-pull-request",
              "title": "Source Control"
            }
          }
        ],
        "currentTab": 4
      }
    ],
    "direction": "horizontal",
    "width": 300
  },
  "left-ribbon": {
    "hiddenItems": {
      "obsidian-git:Open Git source control": false,
      "switcher:Open quick switcher": false,
      "graph:Open graph view": false,
      "canvas:Create new canvas": false,
      "daily-notes:Open today's daily note": false,
      "templates:Insert template": false,
      "command-palette:Open command palette": false
    }
  },
  "active": "b8c5e33dba75b402",
  "lastOpenFiles": [
    "README.md",
    "Reinforcement learning/Note.md",
    "Reinforcement learning/DP.pdf",
    "Reinforcement learning/Theory/Untitled.md",
    "Machine Learning/Excercise/Linear regression math..md",
    "Hardware for Deep Learning/Note.md",
    "Big Data Techniques and Technologies/1. Giới thiệu chung về dữ liệu lớn.md",
    "try.md",
    "Data mining and analytics/Theory/Data Clustering.md",
    "Reinforcement learning/Theory/3. Finite Markov Decision Processes/3.1 The Agent-Environment Interface.md",
    "conflict-files-obsidian-git.md",
    "Reinforcement learning/Theory/3. Finite Markov Decision Processes/Synopsis.md",
    "Reinforcement learning/Theory/3. Finite Markov Decision Processes",
    "Pasted image 20241106160428.png",
    "Data mining and analytics/Theory/Data Understanding.md",
    "Data mining and analytics/Theory/Data preprocessing and preparation.md",
    "Data mining and analytics/Theory/Distance and Similarity.md",
    "Machine Learning/Theory/1. Introduction/1. Machine Learning Exemplified.md",
    "Machine Learning/Theory/1. Introduction/2. About the book.md",
    "Machine Learning/Theory/5. Learning Parametric Models/4. Parameter Optimization.md",
    "Machine Learning/Theory/5. Learning Parametric Models/5. Optimization with Large Datasets.md",
    "preamble.sty~",
    "Machine Learning/Theory/5. Learning Parametric Models/2. Loss Functions and Likelihood-Based Models.md",
    "custom.css~",
    "custom.css",
    "Machine Learning/Theory/2. Supervised Learning - A first Approach/2. A Distance Based Method - k-NN.md",
    "Data mining and analytics/AIT3003 - Khai phá và phân tích dữ liệu/books/Book1-DataMining-ConceptsAndTechniques(3rdEd).pdf",
    "Data mining and analytics/Theory/An Introduction to Data Mining/1. Introduction.md",
    "Reinforcement learning/Note from slides/Lecture 3.md",
    "Reinforcement learning/Theory/2. Multi-armed Bandits/2.8 Gradient Bandit Algorithms.md",
    "Reinforcement learning/Note from slides",
    "Reinforcement learning/Theory/2. Multi-armed Bandits/2.1 A k-armed Bandit Problem.md",
    "Machine Learning/Theory/3. Basic parametric models/2. Classification and Logistic Regression.md",
    "Reinforcement learning/Theory/2. Multi-armed Bandits/2.7 Upper-Confidence-Bound Action Selection.md",
    "Probability and Statistics/Dimitri P. Bertsekas, John N. Tsitsiklis - Introduction to Probability, 2nd Edition  -Athena Scientific (2008).pdf",
    "Probability and Statistics/Dimitri P. Bertsekas and John N. Tsitsiklis - Introduction to Probability 2nd Edition Problem Solutions-Athena Scientific (2019).pdf",
    "Pasted image 20241006192104.png",
    "Pasted image 20241002094328.png",
    "Probability and Statistics/Theory/5. Limit Theorems",
    "Pasted image 20240811224417.png",
    "Pasted image 20240811100800.png",
    "Pasted image 20240810222006.png",
    "Pasted image 20240810213129.png",
    "Pasted image 20240810203655.png",
    "Pasted image 20240810203638.png",
    "Pasted image 20240810202859.png"
  ]
}